{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a108af04",
   "metadata": {},
   "source": [
    "This is a starter notebook for the project, you'll have to import the libraries you'll need, you can find a list of the ones available in this workspace in the requirements.txt file in this workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5fea171213889",
   "metadata": {},
   "source": [
    "# Step 0: Load the Vocareum Key and Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf50522a55436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vocareum import load_vocareum_key\n",
    "\n",
    "\n",
    "load_vocareum_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe938aedfb4594f",
   "metadata": {},
   "source": [
    "# Step 1: Setting Up the Python Application and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce845fdf8009b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import Model, ImageGenerator\n",
    "from src.schemas import PropertyDetails, print_schemas, CreateRealEstateListingsPrompt\n",
    "from src.read_write_ops import save_df_in_csv, read_df_from_csv\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a27d444a52247",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Model().llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589230e2b9f8c1cc",
   "metadata": {},
   "source": [
    "# Step 2: Generating Real Estate Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe176c-a633-4dce-a3b3-161778a1f1fa",
   "metadata": {},
   "source": [
    "We used an LLM (Language Model) to generate diverse property descriptions. Once these descriptions were created, we utilized them to generate corresponding images using the model \"runwayml/stable-diffusion-v1-5\", a text-to-image generation model. This allowed us to pair each listing's detailed description with a visually representative image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4bc0323b1e38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_example = PropertyDetails(\n",
    "    neighborhood=\"Green Oaks\",\n",
    "    price=800000,\n",
    "    bedrooms=3,\n",
    "    bathrooms=2,\n",
    "    house_size=2000,\n",
    "    description=\"Welcome to this eco-friendly oasis nestled in the heart of Green Oaks. This charming 3-bedroom, 2-bathroom home boasts energy-efficient features such as solar panels and a well-insulated structure. Natural light floods the living spaces, highlighting the beautiful hardwood floors and eco-conscious finishes. The open-concept kitchen and dining area lead to a spacious backyard with a vegetable garden, perfect for the eco-conscious family. Embrace sustainable living without compromising on style in this Green Oaks gem.\",\n",
    "    neighborhood_description=\"Green Oaks is a close-knit, environmentally-conscious community with access to organic grocery stores, community gardens, and bike paths. Take a stroll through the nearby Green Oaks Park or grab a cup of coffee at the cozy Green Bean Cafe. With easy access to public transportation and bike lanes, commuting is a breeze.\"\n",
    ")\n",
    "property_example_text = print_schemas(property_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63172f0e781e2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_state_csv_path = Path(\"real_estate_listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c74229400c89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_generated_images_to_listings(real_state_df):\n",
    "    for index, row in real_state_df.iterrows():\n",
    "        try:\n",
    "            output_path = f\"property_{index}.png\"\n",
    "            image_gen = ImageGenerator(row[\"description\"], output_path)\n",
    "            real_state_df.loc[index, \"image_path\"] = image_gen.img_path\n",
    "            image_gen.generate()\n",
    "        except Exception as e:\n",
    "            ValueError(f\"Failed to generate image for row {index}: {e}\")\n",
    "    return real_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683ff4b08126f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_state_csv_path.exists():\n",
    "    df = read_df_from_csv(real_state_csv_path)\n",
    "else:\n",
    "    real_state_listings_prompt = CreateRealEstateListingsPrompt()\n",
    "    query = real_state_listings_prompt.prepare_query(property_example_text=property_example_text)\n",
    "    response = llm.invoke(query)\n",
    "    df = real_state_listings_prompt.convert_response_to_df(response)\n",
    "    df = add_generated_images_to_listings(df)\n",
    "    save_df_in_csv(df, real_state_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c63982d5e59aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c56da05f3c4b2",
   "metadata": {},
   "source": [
    "# Step 3: Storing Listings in a Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf291e-9e17-4d60-b028-0e6f29502b8e",
   "metadata": {},
   "source": [
    "We stored the information from the property descriptions and their corresponding images as embeddings in a ChromaDB database. To calculate the embeddings, we used the OpenCLIPEmbeddingFunction, allowing us to leverage both the textual descriptions and the images for similarity searches and future queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a92c5-6bae-460b-8abe-27640e3933b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vector_db import RAGWithChromaClipEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278c2e3-44be-4663-aed2-14dcab8c13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db = RAGWithChromaClipEmbeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804df717-8316-437b-8905-3f1e3e110a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chroma_db.query_db('A quiet neighborhood, good local schools, and convenient shopping options.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a2e4a-d555-488f-a45f-566fb7c34269",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db.display_query_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d57e94-d8e1-49d5-977e-982cb1e97cc2",
   "metadata": {},
   "source": [
    "# Step 4: Building the User Preference Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9da411-470f-4f81-b4cf-bdbb880e5815",
   "metadata": {},
   "source": [
    "This step collects buyer preferences for a property using an AI-driven interactive assistant. The assistant asks predefined questions about the buyer's requirements. The AI listens to responses, stores them in memory, and generates a concise summary of the buyer's needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc14f4-ae49-4c9a-bc1b-939d245dac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.real_state_agent import BuyerCollectorPreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42779f5d-cf6a-4077-a54c-bbc054b9b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = BuyerCollectorPreferences(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dedc4a-317d-4e67-b30b-c1cf075db870",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77cc70-8f40-4132-a3bc-f9f6c574f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e15c09-5715-4c49-aa01-0f1e0791d842",
   "metadata": {},
   "source": [
    "Using the summarized information, we can now query the database containing our property details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c37d58-78ac-4534-8d70-138bca792296",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chroma_db.query_db(collector.summary, 3)\n",
    "chroma_db.display_query_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4346981-e4cd-4812-be89-e6f020bd28a9",
   "metadata": {},
   "source": [
    "# Step 5: Searching Based on Preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d9653-e4f4-42c2-be74-708fa1a3aee1",
   "metadata": {},
   "source": [
    "This step is included at the end of Step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47fdd36-8a01-4496-8f4e-6ad8b7c40ae8",
   "metadata": {},
   "source": [
    "# Step 6: Personalizing Listing Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9a325-3187-488a-bb66-72551d5fcd3d",
   "metadata": {},
   "source": [
    "For each retrieved listing, the LLM tailors the property description to emphasize features that align with the buyerâ€™s preferences, enhancing its appeal. The process strictly maintains factual integrity, ensuring no factual details are altered or invented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef2c25-d37a-42c4-9650-15c312636333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.real_state_agent import ListingAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1160ae-df1f-4e04-aa0d-87d97d631095",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_listings = ListingAugmenter(llm).process(chroma_db.query_results, collector.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea37d2-3b3a-4124-8729-3a1c4d140658",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Based on your preferences, here some suggestions:')\n",
    "for augmented_l, chroma_result in zip(augmented_listings, chroma_db.query_results):\n",
    "    print(augmented_l.content)\n",
    "    chroma_db.display_result(chroma_result)\n",
    "    print('\\n-------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f48fc2-7290-48fa-b1bc-1d252643e480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
